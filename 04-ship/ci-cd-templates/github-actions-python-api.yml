# GitHub Actions Workflow for Python FastAPI/Django Applications
# Place this file in .github/workflows/deploy-api.yml

name: Deploy Python API

on:
  push:
    branches: [main, staging, develop]
  pull_request:
    branches: [main, staging]

env:
  PYTHON_VERSION: '3.11'
  AWS_REGION: us-east-1

jobs:
  # Job 1: Testing & Quality
  test:
    name: Test & Quality Checks
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Lint with flake8
        run: |
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Type checking with mypy
        run: mypy app/ --ignore-missing-imports

      - name: Security check with bandit
        run: bandit -r app/ -f json -o bandit-report.json
        continue-on-error: true

      - name: Run tests with pytest
        run: |
          pytest tests/ \
            --cov=app \
            --cov-report=xml \
            --cov-report=html \
            --junitxml=junit.xml \
            -v
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
          TESTING: true

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          flags: unittests

      - name: Check migration files
        run: python manage.py makemigrations --check --dry-run
        continue-on-error: true

  # Job 2: Build Docker Image
  build:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: test
    outputs:
      image_tag: ${{ steps.meta.outputs.tags }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to Amazon ECR
        uses: aws-actions/amazon-ecr-login@v2
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ env.AWS_REGION }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ secrets.ECR_REGISTRY }}/${{ secrets.ECR_REPOSITORY }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            PYTHON_VERSION=${{ env.PYTHON_VERSION }}
            BUILD_DATE=${{ github.event.repository.updated_at }}
            VCS_REF=${{ github.sha }}

  # Job 3: Deploy to ECS Staging
  deploy-staging:
    name: Deploy to ECS Staging
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/staging' && github.event_name == 'push'
    environment:
      name: staging
      url: https://api-staging.yourapp.com

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Run database migrations
        run: |
          aws ecs run-task \
            --cluster staging-cluster \
            --task-definition migrate-staging \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=[${{ secrets.SUBNET_IDS }}],securityGroups=[${{ secrets.SECURITY_GROUP_ID }}],assignPublicIp=ENABLED}"

          # Wait for migration to complete
          sleep 30

      - name: Update ECS service
        run: |
          aws ecs update-service \
            --cluster staging-cluster \
            --service api-staging \
            --force-new-deployment \
            --task-definition api-staging:latest

      - name: Wait for service stability
        run: |
          aws ecs wait services-stable \
            --cluster staging-cluster \
            --services api-staging

      - name: Run smoke tests
        run: |
          pip install requests pytest
          pytest tests/smoke/ --base-url=https://api-staging.yourapp.com

  # Job 4: Deploy to Production
  deploy-production:
    name: Deploy to ECS Production
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment:
      name: production
      url: https://api.yourapp.com

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Backup database
        run: |
          aws rds create-db-snapshot \
            --db-instance-identifier prod-db \
            --db-snapshot-identifier prod-backup-$(date +%Y%m%d-%H%M%S)

      - name: Run database migrations
        run: |
          aws ecs run-task \
            --cluster production-cluster \
            --task-definition migrate-production \
            --launch-type FARGATE \
            --network-configuration "awsvpcConfiguration={subnets=[${{ secrets.SUBNET_IDS }}],securityGroups=[${{ secrets.SECURITY_GROUP_ID }}],assignPublicIp=ENABLED}"

          # Wait for migration to complete
          sleep 60

      - name: Blue/Green Deployment
        run: |
          # Create new task definition with new image
          TASK_DEFINITION=$(aws ecs describe-task-definition \
            --task-definition api-production \
            --query taskDefinition)

          NEW_TASK_DEF=$(echo $TASK_DEFINITION | \
            jq --arg IMAGE "${{ needs.build.outputs.image_tag }}" \
            '.containerDefinitions[0].image = $IMAGE | del(.taskDefinitionArn, .revision, .status, .requiresAttributes, .compatibilities, .registeredAt, .registeredBy)')

          NEW_TASK_INFO=$(aws ecs register-task-definition \
            --cli-input-json "$NEW_TASK_DEF")

          NEW_REVISION=$(echo $NEW_TASK_INFO | jq -r '.taskDefinition.revision')

          # Update service with new task definition
          aws ecs update-service \
            --cluster production-cluster \
            --service api-production \
            --task-definition api-production:${NEW_REVISION} \
            --deployment-configuration "maximumPercent=200,minimumHealthyPercent=100"

      - name: Wait for deployment
        run: |
          aws ecs wait services-stable \
            --cluster production-cluster \
            --services api-production

      - name: Run smoke tests
        run: |
          pip install requests pytest
          pytest tests/smoke/ --base-url=https://api.yourapp.com

      - name: Rollback on failure
        if: failure()
        run: |
          aws ecs update-service \
            --cluster production-cluster \
            --service api-production \
            --force-new-deployment \
            --task-definition api-production:$(($NEW_REVISION - 1))

      - name: Send deployment notification
        if: always()
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "API Deployment ${{ job.status }}",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": ":rocket: *Production API Deployment*\n*Status:* ${{ job.status }}\n*Environment:* Production\n*Deployed by:* ${{ github.actor }}\n*Commit:* ${{ github.sha }}\n*URL:* https://api.yourapp.com"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # Job 5: Performance Testing
  performance:
    name: Load Testing
    runs-on: ubuntu-latest
    needs: deploy-production
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Run load tests
        run: k6 run tests/load/api-load-test.js
        env:
          BASE_URL: https://api.yourapp.com
          VUS: 100
          DURATION: 5m

      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: k6-results
          path: k6-results.json

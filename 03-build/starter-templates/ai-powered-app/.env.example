# ===================================
# AI-Powered App - Environment Variables
# ===================================
# Copy this file to .env.local and fill in your values

# ===================================
# SUPABASE
# ===================================
# Get these from: https://app.supabase.com/project/_/settings/api

NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# Service role key (server-side only, never expose to client)
SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# Database direct connection (for migrations, optional)
DATABASE_URL=postgresql://postgres:password@db.project.supabase.co:5432/postgres

# ===================================
# OPENAI
# ===================================
# Get your API key from: https://platform.openai.com/api-keys

OPENAI_API_KEY=sk-...
OPENAI_ORG_ID=org-...  # Optional, only if you have multiple orgs

# Model configuration
OPENAI_DEFAULT_MODEL=gpt-4-turbo-preview
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# ===================================
# ANTHROPIC CLAUDE (Optional)
# ===================================
# Get your API key from: https://console.anthropic.com/

ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_DEFAULT_MODEL=claude-3-sonnet-20240229

# ===================================
# AI PROVIDER CONFIGURATION
# ===================================

# Primary AI provider: 'openai' or 'anthropic'
DEFAULT_AI_PROVIDER=openai

# Enable fallback to alternative provider on failure
ENABLE_PROVIDER_FALLBACK=true

# Model selection strategy: 'cost', 'speed', 'quality'
MODEL_SELECTION_STRATEGY=quality

# ===================================
# RAG CONFIGURATION
# ===================================

# Enable Retrieval Augmented Generation
ENABLE_RAG=true

# Vector search configuration
VECTOR_SIMILARITY_THRESHOLD=0.75
VECTOR_SEARCH_TOP_K=5
EMBEDDING_DIMENSIONS=1536

# Text chunking
TEXT_CHUNK_SIZE=512
TEXT_CHUNK_OVERLAP=50

# ===================================
# TOKEN & COST MANAGEMENT
# ===================================

# Maximum tokens per request
MAX_TOKENS_PER_REQUEST=4096

# Maximum cost per request (USD)
MAX_COST_PER_REQUEST=0.50

# Maximum daily cost per user (USD)
MAX_COST_PER_USER_PER_DAY=10.00

# Token budget for conversation history
CONVERSATION_TOKEN_BUDGET=4000

# ===================================
# STREAMING CONFIGURATION
# ===================================

# Enable streaming responses
ENABLE_STREAMING=true

# Streaming chunk size
STREAM_CHUNK_SIZE=10

# Streaming timeout (milliseconds)
STREAM_TIMEOUT=30000

# ===================================
# CACHING (Optional - Upstash Redis)
# ===================================
# Get free Redis from: https://upstash.com/

UPSTASH_REDIS_URL=https://your-redis.upstash.io
UPSTASH_REDIS_TOKEN=your-token

# Cache TTL (seconds)
RESPONSE_CACHE_TTL=3600
EMBEDDING_CACHE_TTL=86400

# Enable semantic caching (more flexible but slower)
ENABLE_SEMANTIC_CACHING=false
SEMANTIC_CACHE_THRESHOLD=0.95

# ===================================
# RATE LIMITING
# ===================================

# Requests per minute (per user)
RATE_LIMIT_REQUESTS_PER_MINUTE=60

# Tokens per minute (per user)
RATE_LIMIT_TOKENS_PER_MINUTE=100000

# Requests per day (per user)
RATE_LIMIT_REQUESTS_PER_DAY=1000

# ===================================
# FILE UPLOAD & PROCESSING
# ===================================

# Maximum file size (bytes) - 10MB default
MAX_FILE_SIZE=10485760

# Allowed file types (comma-separated)
ALLOWED_FILE_TYPES=pdf,txt,md,doc,docx,csv

# Maximum files per upload
MAX_FILES_PER_UPLOAD=5

# File storage path (in Supabase Storage)
STORAGE_BUCKET=documents

# ===================================
# TEMPERATURE & MODEL PARAMETERS
# ===================================

# Default temperature (0 = deterministic, 1 = creative)
DEFAULT_TEMPERATURE=0.7

# Temperature for different use cases
TEMPERATURE_CHAT=0.7
TEMPERATURE_CODE=0.2
TEMPERATURE_CREATIVE=0.9
TEMPERATURE_SUMMARY=0.3

# Top P (nucleus sampling)
DEFAULT_TOP_P=1.0

# Frequency penalty
DEFAULT_FREQUENCY_PENALTY=0.0

# Presence penalty
DEFAULT_PRESENCE_PENALTY=0.0

# ===================================
# CONVERSATION MEMORY
# ===================================

# Maximum messages in conversation history
MAX_CONVERSATION_MESSAGES=50

# Auto-summarize after N messages
AUTO_SUMMARIZE_AFTER=20

# Summary model (cheaper for summarization)
SUMMARY_MODEL=gpt-3.5-turbo

# ===================================
# MONITORING & LOGGING
# ===================================

# Enable detailed AI operation logging
ENABLE_AI_LOGGING=true

# Log level: 'debug', 'info', 'warn', 'error'
LOG_LEVEL=info

# Send usage alerts at threshold percentage
USAGE_ALERT_THRESHOLD=80

# ===================================
# SECURITY & PRIVACY
# ===================================

# Enable data anonymization before sending to AI
ENABLE_DATA_ANONYMIZATION=true

# Require user consent for AI features
REQUIRE_AI_CONSENT=true

# Data retention period (days)
DATA_RETENTION_DAYS=90

# Delete user data on account deletion
DELETE_DATA_ON_ACCOUNT_DELETION=true

# ===================================
# APP CONFIGURATION
# ===================================

NEXT_PUBLIC_APP_URL=http://localhost:3000
NEXT_PUBLIC_APP_NAME=AI-Powered SaaS

# Enable debug mode
NEXT_PUBLIC_DEBUG=false

# ===================================
# OPTIONAL: ANALYTICS & MONITORING
# ===================================

# Sentry (error tracking)
# SENTRY_DSN=https://...@sentry.io/...

# PostHog (product analytics)
# NEXT_PUBLIC_POSTHOG_KEY=phc_...
# NEXT_PUBLIC_POSTHOG_HOST=https://app.posthog.com

# ===================================
# OPTIONAL: EMAIL (for alerts)
# ===================================

# Resend (https://resend.com)
# RESEND_API_KEY=re_...
# EMAIL_FROM=noreply@yourdomain.com

# ===================================
# OPTIONAL: ALTERNATIVE AI PROVIDERS
# ===================================

# Google Vertex AI
# GOOGLE_VERTEX_PROJECT_ID=your-project
# GOOGLE_VERTEX_LOCATION=us-central1

# Azure OpenAI
# AZURE_OPENAI_API_KEY=...
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_OPENAI_DEPLOYMENT=gpt-4

# Cohere
# COHERE_API_KEY=...

# Hugging Face
# HUGGINGFACE_API_KEY=...

# ===================================
# DEVELOPMENT ONLY
# ===================================

# Mock AI responses (for testing without API calls)
MOCK_AI_RESPONSES=false

# Bypass rate limiting in development
BYPASS_RATE_LIMITS=true

# Bypass cost checks in development
BYPASS_COST_LIMITS=true

# ===================================
# FEATURE FLAGS
# ===================================

# Enable experimental features
ENABLE_FUNCTION_CALLING=true
ENABLE_VISION=false
ENABLE_AUDIO=false
ENABLE_IMAGE_GENERATION=false

# Enable multi-modal AI
ENABLE_MULTIMODAL=false

# ===================================
# NOTES
# ===================================

# 1. Never commit .env.local to version control
# 2. Rotate API keys regularly
# 3. Use different keys for dev/staging/production
# 4. Monitor your API usage and costs
# 5. Set up billing alerts in OpenAI/Anthropic dashboards
# 6. Enable rate limiting in production
# 7. Use Supabase RLS policies for data security
# 8. Review and adjust token limits based on usage
# 9. Enable caching to reduce costs
# 10. Test with mock responses before deploying

# ===================================
# QUICK START CHECKLIST
# ===================================

# Required for basic functionality:
# ✓ NEXT_PUBLIC_SUPABASE_URL
# ✓ NEXT_PUBLIC_SUPABASE_ANON_KEY
# ✓ SUPABASE_SERVICE_ROLE_KEY
# ✓ OPENAI_API_KEY

# Recommended for production:
# ✓ ANTHROPIC_API_KEY (fallback)
# ✓ UPSTASH_REDIS_URL (caching)
# ✓ UPSTASH_REDIS_TOKEN (caching)
# ✓ Set rate limits
# ✓ Set cost limits
# ✓ Configure monitoring

# Optional enhancements:
# - Error tracking (Sentry)
# - Analytics (PostHog)
# - Email alerts (Resend)
# - Additional AI providers
